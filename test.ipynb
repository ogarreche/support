{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import time\n",
    " \n",
    "# Start timing\n",
    "start_time = time.time()\n",
    " \n",
    "# Define constants or variables\n",
    "req_cols = ['x', 'y', 'z', 'label']  # For Descriptive accuracy, remove one feature after each run and re-run\n",
    "num_columns = 3  # Fill in the number of columns in your dataset\n",
    " \n",
    "fraction = 0.5  # how much of that database you want to use\n",
    "frac_normal = 0.2  # how much of the normal classification you want to reduce\n",
    "split = 0.70  # how you want to split the train/test data (this is percentage for train)\n",
    " \n",
    "# Model Parameters\n",
    "max_depth = 5\n",
    "min_samples_split = 2\n",
    " \n",
    "# XAI Samples\n",
    "samples = 1\n",
    " \n",
    "# Specify the name of the output text file\n",
    "output_file_name = \"DecisionTree_LIME_output.txt\"\n",
    "with open(output_file_name, \"w\") as f:print('start',file = f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Decision Tree\n",
      "--------------------------------------------------\n",
      "Importing Libraries\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    " \n",
    "print('--------------------------------------------------')\n",
    "print('Decision Tree')\n",
    "print('--------------------------------------------------')\n",
    "print('Importing Libraries')\n",
    "print('--------------------------------------------------')\n",
    " \n",
    "# Load your dataset\n",
    "df = pd.read_csv('mems_dataset.csv', usecols=req_cols)\n",
    " \n",
    "# Separate features (X) and labels (y)\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    " \n",
    "# Train and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=split, random_state=42)\n",
    " \n",
    "# Define the model\n",
    "decision_tree = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "decision_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "# Calculate accuracy\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total:  0.6772748339255369\n",
      "Precision total:  0.665691744594999\n",
      "Recall total:  0.6318754921375198\n",
      "F1 total:  0.6403889067894075\n",
      "BACC total:  0.6318754921375198\n",
      "MCC total:  0.46518415073560554\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "Acc = accuracy_score(y_test, y_pred)\n",
    "Precision = precision_score(y_test, y_pred, average='macro')\n",
    "Recall = recall_score(y_test, y_pred, average='macro')\n",
    "F1 =  f1_score(y_test, y_pred, average='macro')\n",
    "BACC = balanced_accuracy_score(y_test, y_pred)\n",
    "MCC = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "# with open(output_file_name, \"a\") as f:print('Accuracy total: ', Acc,file=f)\n",
    "print('Accuracy total: ', Acc)\n",
    "print('Precision total: ', Precision )\n",
    "print('Recall total: ', Recall )\n",
    "print('F1 total: ', F1 )\n",
    "print('BACC total: ', BACC)\n",
    "print('MCC total: ', MCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0.07 < y <= 0.10', -0.05215384181498105), ('x <= 9.92', -0.16839004304357927), ('z > 0.38', 0.6230655514358153)]\n",
      "Feature '0.07 < y <= 0.10' not found in X_train columns.\n",
      "Feature 'x <= 9.92' not found in X_train columns.\n",
      "Feature 'z > 0.38' not found in X_train columns.\n",
      "Progress: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an explainer object\n",
    "explainer = LimeTabularExplainer(X_train.to_numpy(), feature_names=X_train.columns.values,\n",
    "                                 class_names=np.unique(y_train), discretize_continuous=True)\n",
    " \n",
    "# Generate Lime explanations for each sample in the test set\n",
    "for i in range(samples):\n",
    "    exp = explainer.explain_instance(X_test.iloc[i].values, decision_tree.predict_proba, num_features=num_columns,\n",
    "                                     top_labels=num_columns)\n",
    "    lime_list = exp.as_list()\n",
    "    lime_list.sort()\n",
    "    print(lime_list)\n",
    "    for item in lime_list:\n",
    "        feature_name = item[0]\n",
    "        if feature_name in X_train.columns:\n",
    "            feature_index = X_train.columns.get_loc(feature_name)\n",
    "            feature_val[feature_index] += abs(item[1])\n",
    "        else:\n",
    "            print(f\"Feature '{feature_name}' not found in X_train columns.\")\n",
    " \n",
    "    print('Progress:', 100 * (i + 1) / samples, '%')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Generating Explainer\n",
      "---------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------\n",
      "[('0.07 < y <= 0.10', -0.04233356093230964), ('x <= 9.92', -0.17300541240125006), ('z > 0.38', 0.6345356576897933)]\n",
      "progress 100.0 %\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "z 0.6345356576897933\n",
      "y 0.17300541240125006\n",
      "x 0.04233356093230964\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Generating Sparsity Graph\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "Sparsity =  0.3333333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lime\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Generating Explainer')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "\n",
    "# test.pop ('Label')\n",
    "print('------------------------------------------------------------------------------')\n",
    "\n",
    "#START TIMER MODEL\n",
    "start = time.time()\n",
    "\n",
    "# test2 = test\n",
    "# test = test.to_numpy()\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.to_numpy(), feature_names= list(X_train.columns.values) , class_names=np.unique(y_train) , discretize_continuous=True)\n",
    "# explainer = LimeTabularExplainer(X_train.to_numpy(), feature_names=X_train.columns.values,\n",
    "#                                  class_names=np.unique(y_train), discretize_continuous=True)\n",
    "\n",
    "#creating dict \n",
    "feat_list = req_cols[:-1]\n",
    "# print(feat_list)\n",
    "\n",
    "feat_dict = dict.fromkeys(feat_list, 0)\n",
    "# print(feat_dict)\n",
    "c = 0\n",
    "\n",
    "num_columns = df.shape[1] - 1\n",
    "feature_name = req_cols[:-1]\n",
    "feature_name.sort()\n",
    "# print('lista',feature_name)\n",
    "feature_val = []\n",
    "\n",
    "for i in range(0,num_columns): feature_val.append(0)\n",
    "\n",
    "for i in range(0,samples):\n",
    "\n",
    "# i = sample\n",
    "    # exp = explainer.explain_instance(test[i], rf.predict_proba)\n",
    "    \n",
    "    exp = explainer.explain_instance(X_test.iloc[i].values, decision_tree.predict_proba, num_features=num_columns, top_labels=num_columns)\n",
    "    # exp.show_in_notebook(show_table=True, show_all=True)\n",
    "    \n",
    "    #lime list to string\n",
    "    lime_list = exp.as_list()\n",
    "    lime_list.sort()\n",
    "    print(lime_list)\n",
    "    for j in range (0,num_columns): feature_val[j]+= abs(lime_list[j][1])\n",
    "    # print ('debug here',lime_list[1][1])\n",
    "\n",
    "    # lime_str = ' '.join(str(x) for x in lime_list)\n",
    "    # print(lime_str)\n",
    "\n",
    "\n",
    "    #lime counting features frequency \n",
    "    # for i in feat_list:\n",
    "    #     if i in lime_str:\n",
    "    #         #update dict\n",
    "    #         feat_dict[i] = feat_dict[i] + 1\n",
    "    \n",
    "    c = c + 1 \n",
    "    print ('progress',100*(c/samples),'%')\n",
    "\n",
    "# Define the number you want to divide by\n",
    "divider = samples\n",
    "\n",
    "# Use a list comprehension to divide all elements by the same number\n",
    "feature_val = [x / divider for x in feature_val]\n",
    "\n",
    "# for item1, item2 in zip(feature_name, feature_val):\n",
    "#     print(item1, item2)\n",
    "\n",
    "\n",
    "# Use zip to combine the two lists, sort based on list1, and then unzip them\n",
    "zipped_lists = list(zip(feature_name, feature_val))\n",
    "zipped_lists.sort(key=lambda x: x[1],reverse=True)\n",
    "\n",
    "# Convert the sorted result back into separate lists\n",
    "sorted_list1, sorted_list2 = [list(x) for x in zip(*zipped_lists)]\n",
    "\n",
    "# print(sorted_list1)\n",
    "# print(sorted_list2)\n",
    "print('----------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "for item1, item2 in zip(sorted_list1, sorted_list2):\n",
    "    print(item1, item2)\n",
    "    with open(output_file_name, \"a\") as f:print(item1, item2, file = f)\n",
    "\n",
    "\n",
    "for k in sorted_list1:\n",
    "  with open(output_file_name, \"a\") as f:print(\"df.pop('\",k,\"')\", sep='', file = f)\n",
    "\n",
    "\n",
    "with open(output_file_name, \"a\") as f:print(\"Trial_ =[\", file = f)\n",
    "for k in sorted_list1:\n",
    "  with open(output_file_name, \"a\") as f:print(\"'\",k,\"',\", sep='', file = f)\n",
    "with open(output_file_name, \"a\") as f:print(\"]\", file = f)\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "# # print(feat_dict)\n",
    "# # Sort values in descending order\n",
    "# for k,v in sorted(feat_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "#   print(k,v)\n",
    "\n",
    "# for k,v in sorted(feat_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "#   print(\"df.pop('\",k,\"')\", sep='')\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "with open(output_file_name, \"a\") as f:print('ELAPSE TIME LIME GLOBAL: ',(end - start)/60, 'min',file = f)\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Generating Sparsity Graph')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('')\n",
    "# print(feature_importance)\n",
    "\n",
    "# feature_importance_vals = 'feature_importance_vals'  # Replace with the name of the column you want to extract\n",
    "feature_val = sorted_list2\n",
    "\n",
    "# col_name = 'col_name'  # Replace with the name of the column you want to extract\n",
    "feature_name = sorted_list1\n",
    "\n",
    "# Find the minimum and maximum values in the list\n",
    "min_value = min(feature_val)\n",
    "max_value = max(feature_val)\n",
    "\n",
    "# Normalize the list to the range [0, 1]\n",
    "normalized_list = [(x - min_value) / (max_value - min_value) for x in feature_val]\n",
    "\n",
    "# print(feature_name,normalized_list,'\\n')\n",
    "# for item1, item2 in zip(feature_name, normalized_list):\n",
    "#     print(item1, item2)\n",
    "\n",
    "#calculating Sparsity\n",
    "\n",
    "# Define the threshold\n",
    "threshold = 1e-10\n",
    "\n",
    "# Initialize a count variable to keep track of values below the threshold\n",
    "count_below_threshold = 0\n",
    "\n",
    "# Iterate through the list and count values below the threshold\n",
    "for value in normalized_list:\n",
    "    if value < threshold:\n",
    "        count_below_threshold += 1\n",
    "\n",
    "Sparsity = count_below_threshold/len(normalized_list)\n",
    "Spar = []\n",
    "print('Sparsity = ',Sparsity)\n",
    "X_axis = []\n",
    "#----------------------------------------------------------------------------\n",
    "for i in range(0, 11):\n",
    "    i/10\n",
    "    threshold = i/10\n",
    "    for value in normalized_list:\n",
    "        if value < threshold:\n",
    "            count_below_threshold += 1\n",
    "\n",
    "    Sparsity = count_below_threshold/len(normalized_list)\n",
    "    Spar.append(Sparsity)\n",
    "    X_axis.append(i/10)\n",
    "    count_below_threshold = 0\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "with open(output_file_name, \"a\") as f:print('y_axis_RF = ', Spar ,'', file = f)\n",
    "with open(output_file_name, \"a\") as f:print('x_axis_RF = ', X_axis ,'', file = f)\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "# Create a plot\n",
    "plt.plot(X_axis, Spar, marker='o', linestyle='-')\n",
    "\n",
    "# Set labels for the axes\n",
    "plt.xlabel('X-Axis')\n",
    "plt.ylabel('Y-Axis')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Values vs. X-Axis')\n",
    "\n",
    "# Show the plot\n",
    "# plt.show()\n",
    "plt.savefig('sparsity_RF_LIME.png')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance (Descending Order):\n",
      "x 0.6345356576897933\n",
      "y 0.17300541240125006\n",
      "z 0.04233356093230964\n",
      "Sparsity: [0.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0]\n",
      "Execution time: 0.0005614142947726779 hours\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Calculate feature importance based on Lime explanations\n",
    "feature_val = [x / samples for x in feature_val]  # Divide by the number of samples\n",
    " \n",
    "# Sort and print feature importance\n",
    "zipped_lists = list(zip(X_train.columns.values, feature_val))  # Using X_train.columns.values to get feature names\n",
    "zipped_lists.sort(key=lambda x: x[1], reverse=True)\n",
    " \n",
    "sorted_list1, sorted_list2 = [list(x) for x in zip(*zipped_lists)]\n",
    " \n",
    "print('Feature Importance (Descending Order):')\n",
    "for k, v in zip(sorted_list1, sorted_list2):\n",
    "    print(k, v)\n",
    " \n",
    "# Generate sparsity graph\n",
    "thresholds = [i / 10 for i in range(11)]\n",
    "sparsity_values = []\n",
    " \n",
    "for threshold in thresholds:\n",
    "    count_below_threshold = sum(1 for value in feature_val if value < threshold)\n",
    "    sparsity_values.append(count_below_threshold / len(feature_val))\n",
    " \n",
    "print('Sparsity:', sparsity_values)\n",
    " \n",
    "# Save sparsity graph\n",
    "plt.plot(thresholds, sparsity_values, marker='o', linestyle='-')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Sparsity')\n",
    "plt.title('Sparsity vs. Threshold')\n",
    "plt.savefig('sparsity_DecisionTree_LIME.png')\n",
    "plt.clf()\n",
    " \n",
    "# Write results to output file\n",
    "with open(output_file_name, \"a\") as f:\n",
    "    print('\\n--------------------------------------------------', file=f)\n",
    "    print('Decision Tree', file=f)\n",
    "    print('--------------------------------------------------', file=f)\n",
    "    print('Feature Importance (Descending Order):', file=f)\n",
    "    for k, v in zip(sorted_list1, sorted_list2):\n",
    "        print(k, v, file=f)\n",
    "    print('Accuracy:', accuracy, file=f)\n",
    "    print('Sparsity:', sparsity_values, file=f)\n",
    "    print('Samples:', samples, file=f)\n",
    " \n",
    "# End timing\n",
    "end_time = time.time()\n",
    " \n",
    "# Calculate execution time\n",
    "execution_time = end_time - start_time\n",
    " \n",
    "# Calculate execution time in hours\n",
    "execution_time_hours = execution_time / 3600  # 3600 seconds in an hour\n",
    " \n",
    "# Print execution time in hours\n",
    "print(\"Execution time: %s hours\" % execution_time_hours)\n",
    " \n",
    "# Write execution time to output file in hours\n",
    "with open(output_file_name, \"a\") as f:\n",
    "    print('Execution time:', execution_time_hours, 'hours', file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HITL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
